{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(\n",
    "        train_data,\n",
    "        batch_size = 100,\n",
    "        shuffle = True,\n",
    "        num_workers = 1\n",
    "    ),\n",
    "\n",
    "    'test': DataLoader(\n",
    "        test_data,\n",
    "        batch_size = 100,\n",
    "        shuffle = True,\n",
    "        num_workers = 1\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x20488743860>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x20488480680>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 10, out_channels = 20, kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training = self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(loaders['train'].dataset),\n",
    "                100. * batch_idx / len(loaders['train']), loss.item()\n",
    "            ))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.data.max(1, keepdim = True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    \n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(loaders['test'].dataset),\n",
    "        100. * correct / len(loaders['test'].dataset)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300189\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 1.768859\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 1.159903\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.781020\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.902612\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.567061\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.466488\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.761625\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.655259\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.792342\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.748995\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.564055\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.356248\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.411990\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.791834\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.510581\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.454678\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.413835\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.335015\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.439597\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.452374\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.423317\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.562375\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.431215\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.466754\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.290718\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.568753\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.282201\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.329913\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.430956\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 9643/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.388238\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.244589\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.220411\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.594193\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.326958\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.337151\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.373054\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.549987\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.291724\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.310705\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.468958\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.363163\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.326039\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.303305\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.333300\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.384482\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.440577\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.337256\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.394951\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.275081\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.342433\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.581432\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.325049\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.411136\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.457165\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.269272\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.366465\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.332860\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.214177\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.249421\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 9723/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.393583\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.300031\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.399643\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.263413\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.124171\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.181015\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.169527\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.240489\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.305754\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.287281\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.304528\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.229922\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.401200\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.628575\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.310770\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.321667\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.241659\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.182249\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.256639\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.326093\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.343968\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.295340\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.325728\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.297526\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.285376\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.482947\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.190116\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.183840\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.332876\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.592493\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 9701/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.475782\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.374578\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.230577\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.184262\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.217460\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.117190\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.347895\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.267355\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.349403\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.291729\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.456142\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.280007\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.390791\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.459716\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.469356\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.215546\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.332753\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.134697\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.225930\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.239871\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.308379\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.374489\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.267102\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.289916\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.162753\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.295564\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.312481\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.339330\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.290061\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.335039\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 9731/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.301469\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.267745\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.298438\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.165836\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.236904\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.359160\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.513618\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.410225\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.290234\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.242111\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.289815\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.326465\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.308179\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.286140\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.259585\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.319464\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.204733\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.255673\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.287009\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.271658\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.239586\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.154085\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.373660\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.256245\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.208906\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.279380\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.335427\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.172905\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.311483\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.361115\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 9734/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.324444\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.343733\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.196695\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.282276\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.406016\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.221865\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.265195\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.169885\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.119057\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.224556\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.334275\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.221968\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.332901\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.201141\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.184592\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.267858\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.222281\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.246160\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.167686\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.411336\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.187230\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.205533\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.426029\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.194287\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.268430\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.318713\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.334566\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.273637\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.274396\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.628498\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 9723/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.266752\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.210652\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.259919\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.213140\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.054859\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.222274\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.325374\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.357028\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.245056\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.567851\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.244985\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.202583\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.287404\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.295588\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.312573\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.345187\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.132868\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.158418\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.272464\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.195779\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.151388\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.165935\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.329472\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.253260\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.182795\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.425192\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.241586\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.297237\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.354693\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.342859\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 9768/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.295289\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.395855\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.152303\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.208223\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.251801\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.458599\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.161125\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.384386\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.287782\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.275015\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.177714\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.201680\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.279635\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.334396\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.196558\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.310039\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.300601\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.369194\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.510399\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.305237\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.205610\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.254782\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.451378\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.451934\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.169293\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.225206\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.288651\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.154261\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.222512\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.270187\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 9745/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.335095\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.443376\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.288670\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.388423\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.384709\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.425975\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.204211\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.312801\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.265406\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.349673\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.256251\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.165780\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.240819\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.330427\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.227899\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.286662\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.373289\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.309050\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.252252\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.211603\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.283251\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.379634\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.216582\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.175914\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.219738\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.379501\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.458025\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.215423\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.399271\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.292072\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 9771/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.280458\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 0.391868\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 0.213719\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 0.313201\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.151250\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.180994\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.164345\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 0.340141\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.362134\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 0.428970\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.262282\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 0.381112\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.259204\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 0.197110\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 0.316325\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.197813\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.274007\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 0.109912\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.327960\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 0.345731\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.202064\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 0.336869\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 0.140158\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 0.203216\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.283529\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.418319\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 0.289957\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 0.428096\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.118846\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 0.270485\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 9763/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[10]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim = 1, keepdim = True).item()\n",
    "\n",
    "print('Prediction: {:.4f}'.format(prediction))\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
